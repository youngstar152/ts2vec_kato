{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1239,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "from models import TSEncoder\n",
    "from models.losses import hierarchical_contrastive_loss\n",
    "from utils import take_per_row, split_with_nan, centerize_vary_length_series, torch_pad_nan\n",
    "import math\n",
    "\n",
    "class TS2Vec:\n",
    "    '''The TS2Vec model'''\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dims,\n",
    "        output_dims=320,\n",
    "        hidden_dims=64,\n",
    "        length_dim=10,\n",
    "        depth=10,\n",
    "        # device='cuda',\n",
    "        device='cpu',\n",
    "        lr=0.001,\n",
    "        batch_size=16,\n",
    "        max_train_length=None,\n",
    "        temporal_unit=0,\n",
    "        after_iter_callback=None,\n",
    "        after_epoch_callback=None,\n",
    "        input_total=1\n",
    "    ):\n",
    "        ''' Initialize a TS2Vec model.\n",
    "        \n",
    "        Args:\n",
    "            input_dims (int): The input dimension. For a univariate time series, this should be set to 1.\n",
    "            output_dims (int): The representation dimension.\n",
    "            hidden_dims (int): The hidden dimension of the encoder.\n",
    "            depth (int): The number of hidden residual blocks in the encoder.\n",
    "            device (int): The gpu used for training and inference.\n",
    "            lr (int): The learning rate.\n",
    "            batch_size (int): The batch size.\n",
    "            max_train_length (Union[int, NoneType]): The maximum allowed sequence length for training. For sequence with a length greater than <max_train_length>, it would be cropped into some sequences, each of which has a length less than <max_train_length>.\n",
    "            temporal_unit (int): The minimum unit to perform temporal contrast. When training on a very long sequence, this param helps to reduce the cost of time and memory.\n",
    "            after_iter_callback (Union[Callable, NoneType]): A callback function that would be called after each iteration.\n",
    "            after_epoch_callback (Union[Callable, NoneType]): A callback function that would be called after each epoch.\n",
    "        '''\n",
    "        \n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.lr = lr\n",
    "        self.batch_size = batch_size\n",
    "        self.max_train_length = max_train_length\n",
    "        self.temporal_unit = temporal_unit\n",
    "        \n",
    "        self._net = TSEncoder(input_dims=input_dims, output_dims=output_dims, hidden_dims=hidden_dims, length_dim=length_dim,depth=depth,input_total=input_total).to(self.device)\n",
    "        self.net = torch.optim.swa_utils.AveragedModel(self._net)\n",
    "        self.net.update_parameters(self._net)\n",
    "        \n",
    "        self.after_iter_callback = after_iter_callback\n",
    "        self.after_epoch_callback = after_epoch_callback\n",
    "        \n",
    "        self.n_epochs = 0\n",
    "        self.n_iters = 0\n",
    "    \n",
    "    def fit(self, train_data, n_epochs=None, n_iters=None, verbose=False,save_model=\"test.pth\"):\n",
    "        ''' Training the TS2Vec model.\n",
    "        \n",
    "        Args:\n",
    "            train_data (numpy.ndarray): The training data. It should have a shape of (n_instance, n_timestamps, n_features). All missing data should be set to NaN.\n",
    "            n_epochs (Union[int, NoneType]): The number of epochs. When this reaches, the training stops.\n",
    "            n_iters (Union[int, NoneType]): The number of iterations. When this reaches, the training stops. If both n_epochs and n_iters are not specified, a default setting would be used that sets n_iters to 200 for a dataset with size <= 100000, 600 otherwise.\n",
    "            verbose (bool): Whether to print the training loss after each epoch.\n",
    "            \n",
    "        Returns:\n",
    "            loss_log: a list containing the training losses on each epoch.\n",
    "        '''\n",
    "        assert train_data.ndim == 3\n",
    "        \n",
    "        if n_iters is None and n_epochs is None:\n",
    "            #n_iters 200to400\n",
    "            n_iters = 400 if train_data.size <= 100000 else 600  # default param for n_iters\n",
    "        \n",
    "        if self.max_train_length is not None:\n",
    "            sections = train_data.shape[1] // self.max_train_length\n",
    "            if sections >= 2:\n",
    "                train_data = np.concatenate(split_with_nan(train_data, sections, axis=1), axis=0)\n",
    "\n",
    "        temporal_missing = np.isnan(train_data).all(axis=-1).any(axis=0)\n",
    "        if temporal_missing[0] or temporal_missing[-1]:\n",
    "            train_data = centerize_vary_length_series(train_data)\n",
    "                \n",
    "        train_data = train_data[~np.isnan(train_data).all(axis=2).all(axis=1)]\n",
    "        \n",
    "        train_dataset = TensorDataset(torch.from_numpy(train_data).to(torch.float))\n",
    "        train_loader = DataLoader(train_dataset, batch_size=min(self.batch_size, len(train_dataset)), shuffle=True, drop_last=True)\n",
    "        \n",
    "        optimizer = torch.optim.AdamW(self._net.parameters(), lr=self.lr)\n",
    "        \n",
    "        loss_log = []\n",
    "        best_loss = float('inf')\n",
    "        #スライディングウィンドウなしの時はslide_num=1にしてください\n",
    "        slide_num=1\n",
    "        while True:\n",
    "            if n_epochs is not None and self.n_epochs >= n_epochs:\n",
    "                break\n",
    "            \n",
    "            cum_loss = 0\n",
    "            n_epoch_iters = 0\n",
    "            \n",
    "            interrupted = False\n",
    "            for batch in train_loader:\n",
    "                if n_iters is not None and self.n_iters >= n_iters:\n",
    "                    interrupted = True\n",
    "                    break\n",
    "                \n",
    "                x = batch[0]\n",
    "                if self.max_train_length is not None and x.size(1) > self.max_train_length:\n",
    "                    window_offset = np.random.randint(x.size(1) - self.max_train_length + 1)\n",
    "                    x = x[:, window_offset : window_offset + self.max_train_length]\n",
    "                x = x.to(self.device)\n",
    "                # print(\"x.shape\")\n",
    "                # print(x.shape)\n",
    "                \n",
    "                ts_l = x.size(1)\n",
    "                \n",
    "                if slide_num==1:\n",
    "                    crop_l = np.random.randint(low=2 ** (self.temporal_unit + 1), high=ts_l+1)\n",
    "                else:\n",
    "                    crop_l = np.random.randint(low=slide_num, high=ts_l+1)\n",
    "                #print(crop_l)\n",
    "                crop_left = np.random.randint(ts_l - crop_l + 1)\n",
    "                crop_right = crop_left + crop_l\n",
    "                crop_eleft = np.random.randint(crop_left + 1)\n",
    "                crop_eright = np.random.randint(low=crop_right, high=ts_l + 1)\n",
    "\n",
    "                crop_offset = np.random.randint(low=-crop_eleft, high=ts_l - crop_eright + 1, size=x.size(0))\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                #forwardの処理\n",
    "                #take_per_rowは行列の一部を取り出す関数 各行目でcrop_offset+crop_eleftからcrop_right - crop_eleft個のデータを取り出す\n",
    "                # print(crop_offset + crop_eleft)\n",
    "                # print(crop_right - crop_eleft)\n",
    "                # print(crop_offset + crop_left)\n",
    "                # print(crop_eright - crop_left)\n",
    "                out1,loss_k1 = self._net(take_per_row(x, crop_offset + crop_eleft, crop_right - crop_eleft))\n",
    "                #out11,out12,out13,loss_k_11,loss_k_12,loss_k_13=self._net(take_per_row(x, crop_offset + crop_eleft, crop_right - crop_eleft))\n",
    "                # print(\"crop_l\")\n",
    "                # print(crop_l)\n",
    "                # print(out1.shape)\n",
    "                out1 = out1[:, -crop_l+(slide_num-1):]\n",
    "\n",
    "                # out11 = out11[:, -crop_l+(3-1):]\n",
    "                # out12 = out12[:, -crop_l+(5-1):]\n",
    "                # out13 = out13[:, -crop_l+(7-1):]\n",
    "                # print(out1.shape)\n",
    "                # print(\"\")\n",
    "                out2,loss_k2= self._net(take_per_row(x, crop_offset + crop_left, crop_eright - crop_left))\n",
    "                #out21,out22,out23,loss_k_21,loss_k_22,loss_k_23= self._net(take_per_row(x, crop_offset + crop_left, crop_eright - crop_left))\n",
    "                #print(crop_l)\n",
    "                # print(out2.shape)\n",
    "                out2 = out2[:, :crop_l-(slide_num-1)]\n",
    "\n",
    "                # out21 = out21[:, :crop_l-(3-1)]\n",
    "                # out22 = out22[:, :crop_l-(5-1)]\n",
    "                # out23 = out23[:, :crop_l-(7-1)]\n",
    "                # print(out2.shape)\n",
    "                \n",
    "                loss= hierarchical_contrastive_loss(\n",
    "                    out1,\n",
    "                    out2,\n",
    "                    temporal_unit=self.temporal_unit\n",
    "                )\n",
    "\n",
    "                # loss1 = hierarchical_contrastive_loss(\n",
    "                #     out11,\n",
    "                #     out21,\n",
    "                #     temporal_unit=self.temporal_unit\n",
    "                # )\n",
    "                # loss2 = hierarchical_contrastive_loss(\n",
    "                #     out12,\n",
    "                #     out22,\n",
    "                #     temporal_unit=self.temporal_unit\n",
    "                # )\n",
    "                # loss3 = hierarchical_contrastive_loss(\n",
    "                #     out13,\n",
    "                #     out23,\n",
    "                #     temporal_unit=self.temporal_unit\n",
    "                # )\n",
    "                # print(\"loss\")\n",
    "                # print(loss)\n",
    "                \n",
    "                print(\"loss_k1,loss_k2\")\n",
    "                print(loss_k1,loss_k2)\n",
    "                loss += loss_k1*1.2+loss_k2*1.2\n",
    "                #loss=loss1+loss2+loss3\n",
    "                #loss += loss_k1*0.1+loss_k2*0.1\n",
    "                \n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                self.net.update_parameters(self._net)\n",
    "                    \n",
    "                cum_loss += loss.item()\n",
    "                n_epoch_iters += 1\n",
    "                \n",
    "                self.n_iters += 1\n",
    "                \n",
    "                if self.after_iter_callback is not None:\n",
    "                    self.after_iter_callback(self, loss.item())\n",
    "            \n",
    "            if interrupted:\n",
    "                break\n",
    "            \n",
    "            cum_loss /= n_epoch_iters\n",
    "            if cum_loss < best_loss:\n",
    "                best_loss = cum_loss\n",
    "                print(f\"Best model updated: loss={cum_loss}\")\n",
    "                loss_log.append(cum_loss)\n",
    "                torch.save(self.net.state_dict(), save_model)\n",
    "            \n",
    "                #torch.save(model.state_dict(), 'best_model.pth')\n",
    "            if verbose:\n",
    "                print(f\"Epoch #{self.n_epochs}: loss={cum_loss}\")\n",
    "            self.n_epochs += 1\n",
    "            \n",
    "            if self.after_epoch_callback is not None:\n",
    "                self.after_epoch_callback(self, cum_loss)\n",
    "            \n",
    "        return loss_log\n",
    "    \n",
    "    def _eval_with_pooling(self, x, mask=None, slicing=None, encoding_window=None):\n",
    "        out ,_loss= self.net(x.to(self.device, non_blocking=True), mask)\n",
    "        if encoding_window == 'full_series':\n",
    "            if slicing is not None:\n",
    "                out = out[:, slicing]\n",
    "            out = F.max_pool1d(\n",
    "                out.transpose(1, 2),\n",
    "                kernel_size = out.size(1),\n",
    "            ).transpose(1, 2)\n",
    "            \n",
    "        elif isinstance(encoding_window, int):\n",
    "            out = F.max_pool1d(\n",
    "                out.transpose(1, 2),\n",
    "                kernel_size = encoding_window,\n",
    "                stride = 1,\n",
    "                padding = encoding_window // 2\n",
    "            ).transpose(1, 2)\n",
    "            if encoding_window % 2 == 0:\n",
    "                out = out[:, :-1]\n",
    "            if slicing is not None:\n",
    "                out = out[:, slicing]\n",
    "            \n",
    "        elif encoding_window == 'multiscale':\n",
    "            p = 0\n",
    "            reprs = []\n",
    "            while (1 << p) + 1 < out.size(1):\n",
    "                t_out = F.max_pool1d(\n",
    "                    out.transpose(1, 2),\n",
    "                    kernel_size = (1 << (p + 1)) + 1,\n",
    "                    stride = 1,\n",
    "                    padding = 1 << p\n",
    "                ).transpose(1, 2)\n",
    "                if slicing is not None:\n",
    "                    t_out = t_out[:, slicing]\n",
    "                reprs.append(t_out)\n",
    "                p += 1\n",
    "            out = torch.cat(reprs, dim=-1)\n",
    "            \n",
    "        else:\n",
    "            if slicing is not None:\n",
    "                out = out[:, slicing]\n",
    "            \n",
    "        return out.cpu()\n",
    "    \n",
    "    def encode(self, data, mask=None, encoding_window=None, causal=False, sliding_length=None, sliding_padding=0, batch_size=None):\n",
    "        ''' Compute representations using the model.\n",
    "        \n",
    "        Args:\n",
    "            data (numpy.ndarray): This should have a shape of (n_instance, n_timestamps, n_features). All missing data should be set to NaN.\n",
    "            mask (str): The mask used by encoder can be specified with this parameter. This can be set to 'binomial', 'continuous', 'all_true', 'all_false' or 'mask_last'.\n",
    "            encoding_window (Union[str, int]): When this param is specified, the computed representation would the max pooling over this window. This can be set to 'full_series', 'multiscale' or an integer specifying the pooling kernel size.\n",
    "            causal (bool): When this param is set to True, the future informations would not be encoded into representation of each timestamp.\n",
    "            sliding_length (Union[int, NoneType]): The length of sliding window. When this param is specified, a sliding inference would be applied on the time series.\n",
    "            sliding_padding (int): This param specifies the contextual data length used for inference every sliding windows.\n",
    "            batch_size (Union[int, NoneType]): The batch size used for inference. If not specified, this would be the same batch size as training.\n",
    "            \n",
    "        Returns:\n",
    "            repr: The representations for data.\n",
    "        '''\n",
    "        assert self.net is not None, 'please train or load a net first'\n",
    "        assert data.ndim == 3\n",
    "        if batch_size is None:\n",
    "            batch_size = self.batch_size\n",
    "        n_samples, ts_l, _ = data.shape\n",
    "\n",
    "        org_training = self.net.training\n",
    "        self.net.eval()\n",
    "        \n",
    "        dataset = TensorDataset(torch.from_numpy(data).to(torch.float))\n",
    "        loader = DataLoader(dataset, batch_size=batch_size)\n",
    "        print(\"a\")\n",
    "        with torch.no_grad():\n",
    "            output = []\n",
    "            for batch in loader:\n",
    "                x = batch[0]\n",
    "                if sliding_length is not None:\n",
    "                    reprs = []\n",
    "                    if n_samples < batch_size:\n",
    "                        calc_buffer = []\n",
    "                        calc_buffer_l = 0\n",
    "                    for i in range(0, ts_l, sliding_length):\n",
    "                        l = i - sliding_padding\n",
    "                        r = i + sliding_length + (sliding_padding if not causal else 0)\n",
    "                        x_sliding = torch_pad_nan(\n",
    "                            x[:, max(l, 0) : min(r, ts_l)],\n",
    "                            left=-l if l<0 else 0,\n",
    "                            right=r-ts_l if r>ts_l else 0,\n",
    "                            dim=1\n",
    "                        )\n",
    "                        if n_samples < batch_size:\n",
    "                            if calc_buffer_l + n_samples > batch_size:\n",
    "                                out = self._eval_with_pooling(\n",
    "                                    torch.cat(calc_buffer, dim=0),\n",
    "                                    mask,\n",
    "                                    slicing=slice(sliding_padding, sliding_padding+sliding_length),\n",
    "                                    encoding_window=encoding_window\n",
    "                                )\n",
    "                                reprs += torch.split(out, n_samples)\n",
    "                                calc_buffer = []\n",
    "                                calc_buffer_l = 0\n",
    "                            calc_buffer.append(x_sliding)\n",
    "                            calc_buffer_l += n_samples\n",
    "                        else:\n",
    "                            out = self._eval_with_pooling(\n",
    "                                x_sliding,\n",
    "                                mask,\n",
    "                                slicing=slice(sliding_padding, sliding_padding+sliding_length),\n",
    "                                encoding_window=encoding_window\n",
    "                            )\n",
    "                            reprs.append(out)\n",
    "\n",
    "                    if n_samples < batch_size:\n",
    "                        if calc_buffer_l > 0:\n",
    "                            out = self._eval_with_pooling(\n",
    "                                torch.cat(calc_buffer, dim=0),\n",
    "                                mask,\n",
    "                                slicing=slice(sliding_padding, sliding_padding+sliding_length),\n",
    "                                encoding_window=encoding_window\n",
    "                            )\n",
    "                            reprs += torch.split(out, n_samples)\n",
    "                            calc_buffer = []\n",
    "                            calc_buffer_l = 0\n",
    "                    \n",
    "                    out = torch.cat(reprs, dim=1)\n",
    "                    if encoding_window == 'full_series':\n",
    "                        out = F.max_pool1d(\n",
    "                            out.transpose(1, 2).contiguous(),\n",
    "                            kernel_size = out.size(1),\n",
    "                        ).squeeze(1)\n",
    "                else:\n",
    "                    out = self._eval_with_pooling(x, mask, encoding_window=encoding_window)\n",
    "                    if encoding_window == 'full_series':\n",
    "                        out = out.squeeze(1)\n",
    "                        \n",
    "                output.append(out)\n",
    "                \n",
    "            output = torch.cat(output, dim=0)\n",
    "            \n",
    "        self.net.train(org_training)\n",
    "        return output.numpy()\n",
    "    \n",
    "    def save(self, fn):\n",
    "        ''' Save the model to a file.\n",
    "        \n",
    "        Args:\n",
    "            fn (str): filename.\n",
    "        '''\n",
    "        torch.save(self.net.state_dict(), fn)\n",
    "    \n",
    "    def load(self, fn):\n",
    "        ''' Load the model from a file.\n",
    "        \n",
    "        Args:\n",
    "            fn (str): filename.\n",
    "        '''\n",
    "        state_dict = torch.load(fn, map_location=self.device)\n",
    "        self.net.load_state_dict(state_dict)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1240,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TripletEmbeddingCriterion(nn.Module):\n",
    "    def __init__(self, margin=0.5, gamma=2):\n",
    "        super(TripletEmbeddingCriterion, self).__init__()\n",
    "        self.margin = margin\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, anchor, positive, negative):\n",
    "        N = anchor.size(0)\n",
    "        \n",
    "        delta_pos = anchor - positive\n",
    "        delta_neg = anchor - negative\n",
    "\n",
    "        norm_delta_pos = torch.norm(delta_pos, p=2, dim=1)\n",
    "        norm_delta_neg = torch.norm(delta_neg, p=2, dim=1)\n",
    "\n",
    "        norm_delta_pos = norm_delta_pos * norm_delta_pos * self.gamma\n",
    "        norm_delta_neg = norm_delta_neg * norm_delta_neg\n",
    "\n",
    "        delta_pos_neg = norm_delta_pos - norm_delta_neg + self.margin\n",
    "\n",
    "        loss = F.relu(delta_pos_neg)\n",
    "        return loss.mean()\n",
    "\n",
    "    def backward(self, anchor, positive, negative):\n",
    "        N = anchor.size(0)\n",
    "        \n",
    "        delta_pos = anchor - positive\n",
    "        delta_neg = anchor - negative\n",
    "\n",
    "        norm_delta_pos = torch.norm(delta_pos, p=2, dim=1)\n",
    "        norm_delta_neg = torch.norm(delta_neg, p=2, dim=1)\n",
    "\n",
    "        norm_delta_pos = norm_delta_pos * norm_delta_pos * self.gamma\n",
    "        norm_delta_neg = norm_delta_neg * norm_delta_neg\n",
    "\n",
    "        delta_pos_neg = norm_delta_pos - norm_delta_neg + self.margin\n",
    "\n",
    "        mask = (delta_pos_neg > 0).float().view(-1, 1)\n",
    "\n",
    "        grad_anchor = mask * (delta_neg - delta_pos * self.gamma) * (2 / N)\n",
    "        grad_positive = mask * (delta_pos * self.gamma) * (-2 / N)\n",
    "        grad_negative = mask * delta_neg * (2 / N)\n",
    "\n",
    "        return grad_anchor, grad_positive, grad_negative\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1241,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def torch_fix_seed(seed=42):\n",
    "    # Python random\n",
    "    random.seed(seed)\n",
    "    # Numpy\n",
    "    np.random.seed(seed)\n",
    "    # Pytorch\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    #torch.use_deterministic_algorithms = True\n",
    "\n",
    "\n",
    "torch_fix_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1242,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class AggClustering:\n",
    "    def __init__(self):\n",
    "        self.K_c = 5\n",
    "\n",
    "    def init(self, indices):\n",
    "        # nsamples = indices.size(0)\n",
    "        # visited = torch.full((nsamples, 1), -1, dtype=torch.int32)\n",
    "        # count = 0\n",
    "        # for i in range(nsamples):\n",
    "        #     cur_idx = i\n",
    "        #     pos = []\n",
    "        #     while visited[cur_idx, 0] == -1:\n",
    "        #         pos.append(cur_idx)\n",
    "        #         neighbor = 0\n",
    "        #         for k in range(indices.size(0)):\n",
    "        #             neighbor = indices[cur_idx, k].item()\n",
    "        #             if cur_idx != neighbor:\n",
    "        #                 break\n",
    "        #         visited[cur_idx, 0] = -2\n",
    "        #         cur_idx = neighbor\n",
    "        #         if len(pos) > 50:\n",
    "        #             break\n",
    "        #     if visited[cur_idx, 0] < 0:\n",
    "        #         visited[cur_idx, 0] = count\n",
    "        #         count += 1\n",
    "        #     for p in pos:\n",
    "        #         visited[p, 0] = visited[cur_idx, 0]\n",
    "        # label_indice = [[] for _ in range(count)]\n",
    "        # for i in range(nsamples):\n",
    "        #     label_indice[visited[i, 0]].append(i)\n",
    "        # return label_indice\n",
    "\n",
    "        # Initialize labels for input data given KNN indices\n",
    "        nsamples = indices.size(0)\n",
    "        k = indices.size(1)\n",
    "        visited = torch.full((nsamples, 1), -1, dtype=torch.int)\n",
    "        count = 0\n",
    "        \n",
    "        for i in range(nsamples):\n",
    "            cur_idx = i\n",
    "            pos = []\n",
    "            while visited[cur_idx][0] == -1:\n",
    "                pos.append(cur_idx)\n",
    "                neighbor = 0\n",
    "                for k_idx in range(indices[cur_idx].size(0)):\n",
    "                    neighbor = indices[cur_idx][k_idx].item()\n",
    "                    if cur_idx != neighbor:\n",
    "                        break\n",
    "                visited[cur_idx][0] = -2\n",
    "                cur_idx = neighbor\n",
    "                if len(pos) > 50:\n",
    "                    break\n",
    "            \n",
    "            if visited[cur_idx][0] < 0:\n",
    "                visited[cur_idx][0] = count\n",
    "                count += 1\n",
    "            \n",
    "            for j in pos:\n",
    "                visited[j][0] = visited[cur_idx][0]\n",
    "        \n",
    "        label_indices = [[] for _ in range(count)]\n",
    "        \n",
    "        for i in range(nsamples):\n",
    "            label_indices[visited[i][0]].append(i)\n",
    "        \n",
    "        for i in range(count):\n",
    "            if len(label_indices[i]) == 0:\n",
    "                print(\"error\")\n",
    "        \n",
    "        return label_indices\n",
    "\n",
    "    # def merge_two_clusters(self, W, A_s_t, A_us_t, Y_t, idx_c_a, idx_c_b):\n",
    "    #     A_us_t[:, idx_c_a] += A_us_t[:, idx_c_b]\n",
    "    #     nsamples_c_a = len(Y_t[idx_c_a])\n",
    "    #     nsamples_c_b = len(Y_t[idx_c_b])\n",
    "    #     ratio = nsamples_c_a / (nsamples_c_a + nsamples_c_b)\n",
    "    #     A_us_t[idx_c_a, :] *= ratio\n",
    "    #     A_us_t[idx_c_b, :] *= (1 - ratio)\n",
    "    #     A_us_t[idx_c_a, :] += A_us_t[idx_c_b, :]\n",
    "    #     A_us_t[idx_c_a, idx_c_a] = 0\n",
    "    #     A_us_t[:, idx_c_b] = 0\n",
    "    #     A_us_t[idx_c_b, :] = 0\n",
    "    #     Y_t[idx_c_a].extend(Y_t[idx_c_b])\n",
    "    #     Y_t[idx_c_b] = []\n",
    "    #     for i in range(len(Y_t)):\n",
    "    #         if len(Y_t[i]) == 0 or i == idx_c_a:\n",
    "    #             A_s_t[i, idx_c_a] = 0\n",
    "    #             A_s_t[idx_c_a, i] = 0\n",
    "    #         elif i < idx_c_a:\n",
    "    #             A_s_t[i, idx_c_a] = A_us_t[idx_c_a, i] / len(Y_t[idx_c_a])**2 + A_us_t[i, idx_c_a] / len(Y_t[i])**2\n",
    "    #         elif i > idx_c_a:\n",
    "    #             A_s_t[idx_c_a, i] = A_us_t[idx_c_a, i] / len(Y_t[idx_c_a])**2 + A_us_t[i, idx_c_a] / len(Y_t[i])**2\n",
    "    #     return A_s_t, A_us_t, Y_t\n",
    "\n",
    "\n",
    "    def merge_two_clusters(W, A_s_t, A_us_t, Y_t, idx_c_a, idx_c_b):\n",
    "        nclusters = len(Y_t)\n",
    "\n",
    "        idx_c_a_tensor = torch.tensor([idx_c_a], dtype=torch.long)\n",
    "        idx_c_b_tensor = torch.tensor([idx_c_b], dtype=torch.long)\n",
    "\n",
    "        A_us_t.index_add_(1, idx_c_a_tensor, A_us_t.index_select(1, idx_c_b_tensor))\n",
    "\n",
    "        nsamples_c_a = len(Y_t[idx_c_a])\n",
    "        nsamples_c_b = len(Y_t[idx_c_b])\n",
    "        ratio = nsamples_c_a / (nsamples_c_a + nsamples_c_b)\n",
    "\n",
    "        A_us_t[idx_c_a, :] *= ratio\n",
    "        A_us_t[idx_c_b, :] *= (1 - ratio)\n",
    "        A_us_t.index_add_(0, idx_c_a_tensor, A_us_t.index_select(0, idx_c_b_tensor))\n",
    "\n",
    "        A_us_t[idx_c_a, idx_c_a] = 0\n",
    "        A_us_t[:, idx_c_b] = 0\n",
    "        A_us_t[idx_c_b, :] = 0\n",
    "\n",
    "        Y_t[idx_c_a].extend(Y_t[idx_c_b])\n",
    "        Y_t[idx_c_b] = []\n",
    "\n",
    "        for i in range(nclusters):\n",
    "            if len(Y_t[i]) == 0 or i == idx_c_a:\n",
    "                A_s_t[i, idx_c_a] = 0\n",
    "                A_s_t[idx_c_a, i] = 0\n",
    "            elif i < idx_c_a:\n",
    "                A_s_t[i, idx_c_a] = A_us_t[idx_c_a, i] / (len(Y_t[idx_c_a]) ** 2) + A_us_t[i, idx_c_a] / (len(Y_t[i]) ** 2)\n",
    "            elif i > idx_c_a:\n",
    "                A_s_t[idx_c_a, i] = A_us_t[idx_c_a, i] / (len(Y_t[idx_c_a]) ** 2) + A_us_t[i, idx_c_a] / (len(Y_t[i]) ** 2)\n",
    "\n",
    "        return A_s_t, A_us_t, Y_t\n",
    "\n",
    "    # def search_clusters(self, A_s_t):\n",
    "    #     A_sorted, idx_sort = torch.sort(A_s_t, dim=1, descending=True)\n",
    "    #     aff = torch.zeros(1, A_sorted.size(1))\n",
    "    #     for i in range(A_sorted.size(1)):\n",
    "    #         aff[0, i] = A_sorted[0, i]\n",
    "    #         if A_sorted.size(1) > 100:\n",
    "    #             for k in range(1, self.K_c):\n",
    "    #                 aff[0, i] += (A_sorted[0, i] - A_sorted[k, i]) / (self.K_c - 1)\n",
    "    #     v_c, idx_c = torch.max(aff, 1)\n",
    "    #     idx_c_b = idx_c.item()\n",
    "    #     idx_c_a = idx_sort[0, idx_c_b].item()\n",
    "    #     if idx_c_a == idx_c_b:\n",
    "    #         raise ValueError(\"Error: idx_c_a == idx_c_b\")\n",
    "    #     if idx_c_a > idx_c_b:\n",
    "    #         idx_c_a, idx_c_b = idx_c_b, idx_c_a\n",
    "    #     return idx_c_a, idx_c_b\n",
    "\n",
    "    def search_clusters(self, A_s_t):\n",
    "        # print(\"cluster numbers:\", nclusters)\n",
    "        nclusters = A_s_t.size(0)  # クラスタの数を取得\n",
    "        A_sorted, idx_sort = torch.sort(A_s_t, dim=0, descending=True)\n",
    "        # print(\"A_s_t: \", A_s_t.size())\n",
    "        # print(\"nclusters: \", nclusters)\n",
    "        # print(\"A_sorted: \", A_sorted)\n",
    "        # print(\"idx_sort: \", idx_sort)\n",
    "        aff = torch.zeros(1, A_sorted.size(1), dtype=torch.float32)\n",
    "\n",
    "        for i in range(A_sorted.size(1)):\n",
    "            aff[0, i] = A_sorted[0, i]\n",
    "            if A_sorted.size(1) > 100:\n",
    "                for k in range(1, self.K_c):\n",
    "                    aff[0, i] += (A_sorted[0, i] - A_sorted[k, i]) / (self.K_c - 1)\n",
    "\n",
    "        v_c, idx_c = torch.max(aff, dim=1)  # each row\n",
    "        # print(\"idx_c: \", idx_c)\n",
    "        # find corresponding cluster labels for two clusters\n",
    "        idx_c_b = idx_c[0].item()         # col\n",
    "        idx_c_a = idx_sort[0, idx_c_b].item()        # row\n",
    "\n",
    "        # インデックスの検証と調整\n",
    "        if idx_c_a >= nclusters or idx_c_b >= nclusters:\n",
    "            raise ValueError(f\"Error: idx_c_a ({idx_c_a}) or idx_c_b ({idx_c_b}) is out of range (nclusters: {nclusters})\")\n",
    "        if idx_c_a == idx_c_b:\n",
    "            print(\"error\")\n",
    "            raise ValueError(\"idx_c_a and idx_c_b are the same\")\n",
    "        elif idx_c_a > idx_c_b:\n",
    "            idx_c_a, idx_c_b = idx_c_b, idx_c_a\n",
    "\n",
    "        return idx_c_a, idx_c_b\n",
    "\n",
    "    # def search_clusters(self,A_s_t):\n",
    "    #     # Sort the tensor along the first dimension in descending order\n",
    "    #     A_sorted, Idx_sort = torch.sort(A_s_t, dim=0, descending=True)\n",
    "        \n",
    "    #     # Initialize affinity tensor\n",
    "    #     aff = torch.zeros(1, A_sorted.size(1))\n",
    "        \n",
    "    #     for i in range(A_sorted.size(1)):\n",
    "    #         aff[0, i] = A_sorted[0, i]\n",
    "    #         if A_sorted.size(1) > 100:\n",
    "    #             for k in range(1, self.K_c ):  # Adjusting index for Python's 0-based indexing\n",
    "    #                 aff[0, i] += (A_sorted[0, i] - A_sorted[k, i]) / (self.K_c - 1)\n",
    "        \n",
    "    #     # Find the maximum value in the affinity tensor along the second dimension\n",
    "    #     v_c, idx_c = torch.max(aff, dim=1)\n",
    "        \n",
    "    #     # Find corresponding cluster labels for two clusters\n",
    "    #     idx_c_b = idx_c.item()  # Converting tensor to integer\n",
    "    #     idx_c_a = Idx_sort[0, idx_c_b].item()  # Converting tensor to integer\n",
    "        \n",
    "    #     if idx_c_a == idx_c_b:\n",
    "    #         print(\"error\")\n",
    "    #         raise ValueError(\"Cluster indices are equal, which indicates an error.\")\n",
    "    #     elif idx_c_a > idx_c_b:\n",
    "    #         idx_c_a, idx_c_b = idx_c_b, idx_c_a  # Swap values\n",
    "        \n",
    "    #     return idx_c_a, idx_c_b\n",
    "\n",
    "\n",
    "    def run_step(self, W, A_s_t, A_us_t, Y_t):\n",
    "        nclusters = len(Y_t)\n",
    "        # print(\"Cluster Num: \", nclusters)\n",
    "        # print(\"numc\",A_s_t.size(0))\n",
    "        idx_c_a, idx_c_b = self.search_clusters(A_s_t)\n",
    "        A_us_t[:, idx_c_a] += A_us_t[:, idx_c_b]\n",
    "        Y_t[idx_c_a].extend(Y_t[idx_c_b])\n",
    "        Y_t[idx_c_b] = []\n",
    "        for i in range(len(Y_t)):\n",
    "            if len(Y_t[i]) > 0 and i != idx_c_a:\n",
    "                W_i = W[Y_t[i], :]\n",
    "                W_i_idx_c_a = W_i[:, Y_t[idx_c_a]]\n",
    "                W_idx_c_a = W[Y_t[idx_c_a], :]\n",
    "                W_idx_c_a_i = W_idx_c_a[:, Y_t[i]]\n",
    "                A_us_t[idx_c_a, i] = torch.sum(torch.mm(W_idx_c_a_i, W_i_idx_c_a))\n",
    "        A_us_t[idx_c_a, idx_c_a] = 0\n",
    "        A_us_t[:, idx_c_b] = 0\n",
    "        A_us_t[idx_c_b, :] = 0\n",
    "        for i in range(nclusters):\n",
    "            if len(Y_t[i]) == 0 or i == idx_c_a:\n",
    "                A_s_t[i, idx_c_a] = 0\n",
    "                A_s_t[idx_c_a, i] = 0\n",
    "            elif i < idx_c_a:\n",
    "                A_s_t[i, idx_c_a] = A_us_t[idx_c_a, i] / len(Y_t[idx_c_a])**2 + A_us_t[i, idx_c_a] / len(Y_t[i])**2\n",
    "            elif i > idx_c_a:\n",
    "                A_s_t[idx_c_a, i] = A_us_t[idx_c_a, i] / len(Y_t[idx_c_a])**2 + A_us_t[i, idx_c_a] / len(Y_t[i])**2\n",
    "        A_s_t[:, idx_c_b] = 0\n",
    "        A_s_t[idx_c_b, :] = 0\n",
    "        return A_s_t, A_us_t, Y_t\n",
    "\n",
    "    # def run_step_fast(self,W, A_s_t, A_us_t, Y_t):\n",
    "    #     # timer = torch.Timer()\n",
    "    #     # get the number of clusters\n",
    "    #     nclusters = len(Y_t)\n",
    "    #     print(\"Cluster Num: \", nclusters)\n",
    "    #     print(\"numc\",A_s_t.size(0))\n",
    "    #     # print(\"Cluster Num: \", nclusters)\n",
    "    #     # find maximal value in A_t\n",
    "    #     idx_c_a, idx_c_b = self.search_clusters(A_s_t)\n",
    "    #     # update affinity matrix A_t\n",
    "    #     # update A_t(idx_c_a->i) = A_t(idx_c_a->i) + A_t(idx_c_b->i)\n",
    "    #     A_us_t.index_add_(1, torch.LongTensor([idx_c_a]), A_us_t.index_select(1, torch.LongTensor([idx_c_b])))\n",
    "\n",
    "    #     # update A_t(i->idx_c_a) = r_a * A_t(i->idx_c_a) + r_b * A_t(i->idx_c_b) (fast algorithm)\n",
    "    #     # nsamples in cluster idx_c_a\n",
    "    #     A_us_t.index_add_(0, torch.LongTensor([idx_c_a]), A_us_t.index_select(0, torch.LongTensor([idx_c_b])))\n",
    "        \n",
    "    #     # update cluster labels Y_t   \n",
    "    #     print(\"y_t: \", Y_t)\n",
    "    #     print(\"idx_c_a: \", idx_c_a)\n",
    "    #     print(\"idx_c_b: \", idx_c_b)\n",
    "    #     Y_t[idx_c_a].extend(Y_t[idx_c_b])\n",
    "    #     Y_t[idx_c_b] = []\n",
    "        \n",
    "    #     # update A_s_t   \n",
    "    #     for i in range(nclusters):\n",
    "    #         if len(Y_t[i]) == 0 or i == idx_c_a:\n",
    "    #             A_s_t[i, idx_c_a] = 0\n",
    "    #             A_s_t[idx_c_a, i] = 0\n",
    "    #         elif i < idx_c_a:\n",
    "    #             A_s_t[i, idx_c_a] =  A_us_t[idx_c_a, i] / (len(Y_t[idx_c_a]) ** 2) + A_us_t[i, idx_c_a] / (len(Y_t[i]) ** 2)\n",
    "    #         elif i > idx_c_a:\n",
    "    #             A_s_t[idx_c_a, i] =  A_us_t[idx_c_a, i] / (len(Y_t[idx_c_a]) ** 2) + A_us_t[i, idx_c_a] / (len(Y_t[i]) ** 2)\n",
    "\n",
    "    #     # print(A_us_t.size())\n",
    "    #     # print(nclusters)\n",
    "    #     if idx_c_b != nclusters:\n",
    "    #         # print(idx_c_b)\n",
    "    #         # print(A_us_t.index_select(0, torch.LongTensor([1])))\n",
    "    #         A_us_t.index_copy_(0, torch.LongTensor([idx_c_b]), A_us_t.index_select(0, torch.LongTensor([nclusters-1])))\n",
    "    #         A_us_t.index_copy_(1, torch.LongTensor([idx_c_b]), A_us_t.index_select(1, torch.LongTensor([nclusters-1])))\n",
    "    #         A_us_t[idx_c_b, idx_c_b] = 0\n",
    "\n",
    "    #         # print(\"Pre: \", A_s_t[:idx_c_b+1, idx_c_b])\n",
    "    #         # print(\"Pre: \", A_s_t[idx_c_b, idx_c_b:nclusters])\n",
    "    #         A_s_t[:idx_c_b+1, idx_c_b] = A_s_t[:idx_c_b+1, nclusters-1]      \n",
    "    #         A_s_t[idx_c_b, idx_c_b:nclusters] = A_s_t[idx_c_b:nclusters, nclusters-1].t()\n",
    "    #         A_s_t[idx_c_b, idx_c_b] = 0\n",
    "    #         # print(\"Cur: \", A_s_t[:idx_c_b+1, idx_c_b])\n",
    "    #         # print(\"Cur: \", A_s_t[idx_c_b, idx_c_b:nclusters])\n",
    "\n",
    "    #         Y_t[idx_c_b].extend(Y_t[nclusters-1])\n",
    "\n",
    "    #     A_us_t = A_us_t[:nclusters-1, :nclusters-1]\n",
    "    #     A_s_t = A_s_t[:nclusters-1, :nclusters-1]\n",
    "    #     del Y_t[nclusters-1]   \n",
    "    #     # print(Y_t)\n",
    "    #     # timer = torch.Timer()\n",
    "    #     # print('Time-2 elapsed: ' .. timer:time().real .. ' seconds')\n",
    "    #     # return updated A_s_t, A_us_t and Y_t\n",
    "    #     return A_s_t, A_us_t, Y_t\n",
    "\n",
    "    def run_step_fast(self, W, A_s_t, A_us_t, Y_t):\n",
    "        nclusters = len(Y_t)\n",
    "        idx_c_a, idx_c_b = self.search_clusters(A_s_t)\n",
    "\n",
    "        A_us_t.index_add_(1, torch.LongTensor([idx_c_a]), A_us_t.index_select(1, torch.LongTensor([idx_c_b])))\n",
    "        A_us_t.index_add_(0, torch.LongTensor([idx_c_a]), A_us_t.index_select(0, torch.LongTensor([idx_c_b])))\n",
    "\n",
    "        # print(\"y_t: \", Y_t)\n",
    "        # print(\"idx_c_a: \", idx_c_a)\n",
    "        # print(\"idx_c_b: \", idx_c_b)\n",
    "        Y_t[idx_c_a].extend(Y_t[idx_c_b])\n",
    "        Y_t[idx_c_b] = []\n",
    "\n",
    "        for i in range(nclusters):\n",
    "            if len(Y_t[i]) == 0 or i == idx_c_a:\n",
    "                A_s_t[i, idx_c_a] = 0\n",
    "                A_s_t[idx_c_a, i] = 0\n",
    "            elif i < idx_c_a:\n",
    "                A_s_t[i, idx_c_a] = A_us_t[idx_c_a, i] / (len(Y_t[idx_c_a]) ** 2) + A_us_t[i, idx_c_a] / (len(Y_t[i]) ** 2)\n",
    "            elif i > idx_c_a:\n",
    "                A_s_t[idx_c_a, i] = A_us_t[idx_c_a, i] / (len(Y_t[idx_c_a]) ** 2) + A_us_t[i, idx_c_a] / (len(Y_t[i]) ** 2)\n",
    "\n",
    "        if idx_c_b != nclusters - 1:\n",
    "            A_us_t.index_copy_(0, torch.LongTensor([idx_c_b]), A_us_t.index_select(0, torch.LongTensor([nclusters-1])))\n",
    "            A_us_t.index_copy_(1, torch.LongTensor([idx_c_b]), A_us_t.index_select(1, torch.LongTensor([nclusters-1])))\n",
    "            A_us_t[idx_c_b, idx_c_b] = 0\n",
    "\n",
    "            A_s_t[:idx_c_b+1, idx_c_b] = A_s_t[:idx_c_b+1, nclusters-1].clone()\n",
    "            A_s_t[idx_c_b, idx_c_b:nclusters] = A_s_t[idx_c_b:nclusters, nclusters-1].clone().t()\n",
    "            A_s_t[idx_c_b, idx_c_b] = 0\n",
    "\n",
    "            Y_t[idx_c_b].extend(Y_t[nclusters-1])\n",
    "\n",
    "        # Update the size of A_s_t and A_us_t to match the new number of clusters\n",
    "        A_us_t = A_us_t[:nclusters-1, :nclusters-1]\n",
    "        A_s_t = A_s_t[:nclusters-1, :nclusters-1]\n",
    "        del Y_t[nclusters-1]\n",
    "\n",
    "        return A_s_t, A_us_t, Y_t\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def run(self, W, A_unsym_0, A_sym_0, Y_0, T, K_c_in, use_fast):\n",
    "        nclusters = len(Y_0)\n",
    "        A_sym_0_sum = torch.sum(A_sym_0, dim=1)\n",
    "        self.K_c = K_c_in\n",
    "        t = 0\n",
    "        while t < T:\n",
    "            if use_fast:\n",
    "                A_sym_0, A_unsym_0, Y_0 = self.run_step_fast(W, A_sym_0, A_unsym_0, Y_0)\n",
    "            else:\n",
    "                A_sym_0, A_unsym_0, Y_0 = self.run_step(W, A_sym_0, A_unsym_0, Y_0)\n",
    "            t += 1\n",
    "        Y_T = [cluster for cluster in Y_0 if len(cluster) > 0]\n",
    "        return Y_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1295,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import time\n",
    "\n",
    "class Affinity:\n",
    "    def compute(self, X, k):\n",
    "        print(\"Xtype\", X.dtype)\n",
    "        print(\"k\", k)\n",
    "        if X.size(0) > 50000:\n",
    "            ind = torch.arange(1, X.size(0) + 1).long().split(10000)\n",
    "            dists = torch.zeros(X.size(0), k + 1, dtype=X.dtype)\n",
    "            indices = torch.zeros(X.size(0), k + 1, dtype=torch.int)\n",
    "\n",
    "            for v in ind:\n",
    "                nbrs = NearestNeighbors(n_neighbors=k+1, algorithm='auto').fit(X)\n",
    "                dists_batch, indices_batch = nbrs.kneighbors(X[v - 1])\n",
    "                dists[v - 1] = torch.tensor(dists_batch)\n",
    "                indices[v - 1] = torch.tensor(indices_batch)\n",
    "        else:\n",
    "            print('now')\n",
    "            nbrs = NearestNeighbors(n_neighbors=k+1, algorithm='auto').fit(X)\n",
    "            dists, indices = nbrs.kneighbors(X)\n",
    "            dists = torch.tensor(dists)\n",
    "            indices = torch.tensor(indices)\n",
    "\n",
    "        sigma_square = torch.mean(dists[:, 1:k+1])\n",
    "        print(\"sigma:\", torch.sqrt(sigma_square))\n",
    "\n",
    "        nsamples = X.size(0)\n",
    "        W = torch.zeros(nsamples, nsamples)\n",
    "\n",
    "        for i in range(nsamples):\n",
    "            for j in range(1, k + 1):\n",
    "                nn_ind = indices[i][j]\n",
    "                W[i][nn_ind] = torch.exp(-dists[i][j] / sigma_square)\n",
    "        \n",
    "        return dists, indices, W\n",
    "\n",
    "    def compute4cluster(self, X, W, Y_0, k, k_target):\n",
    "        nclusters = len(Y_0)\n",
    "        dim = X.size(1)\n",
    "        X_clusters = torch.zeros(nclusters, dim)\n",
    "\n",
    "        for i in range(nclusters):\n",
    "            X_clusters[i] = torch.mean(X[torch.LongTensor(Y_0[i])], dim=0)\n",
    "\n",
    "        nbrs = NearestNeighbors(n_neighbors=k, algorithm='auto').fit(X_clusters)\n",
    "        dists, indices = nbrs.kneighbors(X_clusters)\n",
    "        dists = torch.tensor(dists)\n",
    "        indices = torch.tensor(indices)\n",
    "\n",
    "        NNs = torch.zeros(nclusters, nclusters)\n",
    "        # print(indices.size())\n",
    "\n",
    "        for i in range(nclusters):\n",
    "            for j in range(1, indices.size(1)):\n",
    "                nn_ind = indices[i][j]\n",
    "                NNs[i][nn_ind] = 1\n",
    "\n",
    "        max_number = max(len(y) for y in Y_0)\n",
    "        Y_0_tensor = torch.zeros(nclusters, max_number)\n",
    "\n",
    "        for i in range(nclusters):\n",
    "            for j in range(len(Y_0[i])):\n",
    "                Y_0_tensor[i][j] = Y_0[i][j]\n",
    "\n",
    "        timer = time.time()\n",
    "        A_unsym_0_c, A_sym_0_c = self.compute_CAff(W, NNs, Y_0_tensor)\n",
    "\n",
    "        if k > 20 * k_target:\n",
    "            A_unsym_0_c = A_unsym_0_c.double()\n",
    "            A_sym_0_c = A_sym_0_c.double()\n",
    "\n",
    "            A_unsym_0_c_sum_r = torch.sum(A_unsym_0_c, dim=1)\n",
    "            A_unsym_0_c_sum_c = torch.sum(A_unsym_0_c, dim=0)\n",
    "\n",
    "            for i in range(nclusters):\n",
    "                if A_unsym_0_c_sum_r[i] == 0 and A_unsym_0_c_sum_c[i] == 0:\n",
    "                    idx_a = i\n",
    "                    idx_b = 0\n",
    "                    for k in range(indices.size(1)):\n",
    "                        if indices[i][k] != i:\n",
    "                            idx_b = indices[i][k]\n",
    "                            break\n",
    "\n",
    "                    if idx_b > 0:\n",
    "                        if idx_a > idx_b:\n",
    "                            print(\"merge\", idx_b, idx_a)\n",
    "                            A_sym_0_c, A_unsym_0_c, Y_0 = self.merge_two_clusters(W, A_sym_0_c, A_unsym_0_c, Y_0, idx_b, idx_a)\n",
    "                        else:\n",
    "                            print(\"merge\", idx_a, idx_b)\n",
    "                            A_sym_0_c, A_unsym_0_c, Y_0 = self.merge_two_clusters(W, A_sym_0_c, A_unsym_0_c, Y_0, idx_a, idx_b)\n",
    "\n",
    "                        A_unsym_0_c_sum_r = torch.sum(A_unsym_0_c, dim=1)\n",
    "                        A_unsym_0_c_sum_c = torch.sum(A_unsym_0_c, dim=0)\n",
    "\n",
    "        print('Time elapsed for computing cluster affinity:', time.time() - timer, 'seconds')\n",
    "        # print(\"Y_0: \", Y_0)\n",
    "        # print(\"A_unsym_0_c: \", A_unsym_0_c.size())\n",
    "        # print(\"A_sym_0_c: \", A_sym_0_c.size())\n",
    "        return A_unsym_0_c, A_sym_0_c, Y_0\n",
    "\n",
    "    # def compute_CAff(self, W, NNs, Y_0_tensor):\n",
    "    #     # Placeholder function to simulate compute_CAff. Actual implementation required.\n",
    "    #     A_unsym_0_c = torch.rand(W.size())\n",
    "    #     A_sym_0_c = torch.rand(W.size())\n",
    "    #     return A_unsym_0_c, A_sym_0_c\n",
    "\n",
    "    def compute_CAff(self,W, NNs, Y):\n",
    "        nclusters = NNs.size(0)\n",
    "        \n",
    "        A_us = torch.zeros_like(NNs)\n",
    "        A_s = torch.zeros_like(NNs)\n",
    "\n",
    "        for i in range(nclusters):\n",
    "            for j in range(i, nclusters):\n",
    "                if NNs[i, j] == 0 and NNs[j, i] == 0:\n",
    "                    A_us[j, i] = 0\n",
    "                    A_us[i, j] = 0\n",
    "                    A_s[j, i] = 0\n",
    "                    A_s[i, j] = 0\n",
    "                    continue\n",
    "\n",
    "                if i == j:\n",
    "                    A_us[j, i] = 0\n",
    "                    A_s[j, i] = 0\n",
    "                    continue\n",
    "\n",
    "                # get the size of Y[i] and Y[j]\n",
    "                Y_i_size = (Y[i] != 0).sum().item()\n",
    "                Y_j_size = (Y[j] != 0).sum().item()\n",
    "\n",
    "                # compute affinity from cluster i to cluster j\n",
    "                A_c_i_j = 0\n",
    "                for m in range(Y_i_size):\n",
    "                    s_W_c_j_i = 0\n",
    "                    s_W_c_i_j = 0\n",
    "                    for n in range(Y_j_size):\n",
    "                        s_W_c_j_i += W[Y[j, n].long() - 1, Y[i, m].long() - 1]\n",
    "                        s_W_c_i_j += W[Y[i, m].long() - 1, Y[j, n].long() - 1]\n",
    "                    A_c_i_j += s_W_c_j_i * s_W_c_i_j\n",
    "\n",
    "                # compute affinity from cluster j to cluster i\n",
    "                A_c_j_i = 0\n",
    "                for m in range(Y_j_size):\n",
    "                    s_W_c_j_i = 0\n",
    "                    s_W_c_i_j = 0\n",
    "                    for n in range(Y_i_size):\n",
    "                        s_W_c_j_i += W[Y[j, m].long() - 1, Y[i, n].long() - 1]\n",
    "                        s_W_c_i_j += W[Y[i, n].long() - 1, Y[j, m].long() - 1]\n",
    "                    A_c_j_i += s_W_c_i_j * s_W_c_j_i\n",
    "\n",
    "                A_us[j, i] = A_c_i_j\n",
    "                A_us[i, j] = A_c_j_i\n",
    "                A_s[i, j] = A_c_i_j / (Y_j_size ** 2) + A_c_j_i / (Y_i_size ** 2)\n",
    "                A_s[j, i] = 0\n",
    "\n",
    "        return A_us, A_s\n",
    "\n",
    "\n",
    "    def merge_two_clusters(self, W, A_s_t, A_us_t, Y_t, idx_c_a, idx_c_b):\n",
    "        nclusters = len(Y_t)\n",
    "\n",
    "        A_us_t[:, idx_c_a] += A_us_t[:, idx_c_b]\n",
    "\n",
    "        nsamples_c_a = len(Y_t[idx_c_a])\n",
    "        nsamples_c_b = len(Y_t[idx_c_b])\n",
    "        ratio = nsamples_c_a / (nsamples_c_a + nsamples_c_b)\n",
    "\n",
    "        A_us_t[idx_c_a] *= ratio\n",
    "        A_us_t[idx_c_b] *= 1 - ratio\n",
    "        A_us_t[idx_c_a] += A_us_t[idx_c_b]\n",
    "        A_us_t[idx_c_a, idx_c_a] = 0\n",
    "        A_us_t[:, idx_c_b] = 0\n",
    "        A_us_t[idx_c_b, :] = 0\n",
    "\n",
    "        Y_t[idx_c_a].extend(Y_t[idx_c_b])\n",
    "        Y_t[idx_c_b] = []\n",
    "\n",
    "        for i in range(nclusters):\n",
    "            if len(Y_t[i]) == 0 or i == idx_c_a:\n",
    "                A_s_t[i, idx_c_a] = 0\n",
    "                A_s_t[idx_c_a, i] = 0\n",
    "            elif i < idx_c_a:\n",
    "                A_s_t[i, idx_c_a] = A_us_t[idx_c_a, i] / (len(Y_t[idx_c_a]) ** 2) + A_us_t[i, idx_c_a] / (len(Y_t[i]) ** 2)\n",
    "            elif i > idx_c_a:\n",
    "                A_s_t[idx_c_a, i] = A_us_t[idx_c_a, i] / (len(Y_t[idx_c_a]) ** 2) + A_us_t[i, idx_c_a] / (len(Y_t[i]) ** 2)\n",
    "\n",
    "        return A_s_t, A_us_t, Y_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1273,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluate:\n",
    "    def NMI(self, labels_gt, labels_pre):\n",
    "        N = sum(len(l) for l in labels_gt)\n",
    "        # Compute entropy for labels_gt\n",
    "        pr_gt = torch.zeros(len(labels_gt), 1)\n",
    "        for i, label in enumerate(labels_gt):\n",
    "            pr_gt[i] = len(label) / N\n",
    "        pr_gt_log = torch.log(pr_gt)\n",
    "        H_gt = -torch.sum(pr_gt * pr_gt_log)\n",
    "\n",
    "        # Compute entropy for labels_pre\n",
    "        pr_pre = torch.zeros(len(labels_pre), 1)\n",
    "        for i, label in enumerate(labels_pre):\n",
    "            pr_pre[i] = len(label) / N\n",
    "        pr_pre_log = torch.log(pr_pre)\n",
    "        H_pre = -torch.sum(pr_pre * pr_pre_log)\n",
    "\n",
    "        # Compute mutual information\n",
    "        # Build M_gt\n",
    "        M_gt = torch.zeros(N, len(labels_gt))\n",
    "        for i, label in enumerate(labels_gt):\n",
    "            for j in label:\n",
    "                if j < N:  # Ensure the index is within bounds\n",
    "                    M_gt[j, i] = 1  # Keep it zero-based\n",
    "\n",
    "        # Build M_pre\n",
    "        M_pre = torch.zeros(N, len(labels_pre))\n",
    "        for i, label in enumerate(labels_pre):\n",
    "            for j in label:\n",
    "                if j < N:  # Ensure the index is within bounds\n",
    "                    M_pre[j, i] = 1  # Keep it zero-based\n",
    "\n",
    "        pr_gp = torch.mm(M_gt.t(), M_pre) / N\n",
    "        pr_gp_log = torch.log(pr_gp + 1e-10)\n",
    "        H_gp = -torch.sum(pr_gp * pr_gp_log)\n",
    "\n",
    "        # Compute mutual information\n",
    "        MI = H_gt + H_pre - H_gp\n",
    "        NMI = MI / torch.sqrt(H_gt * H_pre)\n",
    "\n",
    "        return NMI.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1274,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import h5py\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import random\n",
    "import os\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 直接スクリプト内で設定するオプション\n",
    "class Options:\n",
    "    dataset = 'custom'\n",
    "    eta = 0.2\n",
    "    epoch_rnn = 1\n",
    "    batchSize = 10\n",
    "    learningRate = 0.01\n",
    "    weightDecay = 5e-5\n",
    "    momentum = 0.9\n",
    "    gamma_lr = 0.0001\n",
    "    power_lr = 0.75\n",
    "    num_nets = 1\n",
    "    epoch_pp = 20\n",
    "    epoch_max = 1000\n",
    "    K_s = 5\n",
    "    K_c = 5\n",
    "    gamma_tr = 1\n",
    "    margin_tr = 0.2\n",
    "    num_nsampling = 5\n",
    "    use_fast = 1\n",
    "    updateCNN = 1\n",
    "    centralize_input = 0\n",
    "    centralize_feature = 0\n",
    "    normalize = 1\n",
    "\n",
    "opt = Options()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\n",
      "(7352, 10)\n",
      "Index([   0.0,    1.0,    2.0,    3.0,    4.0,    5.0,    6.0,    7.0,    8.0,\n",
      "          9.0,\n",
      "       ...\n",
      "       7342.0, 7343.0, 7344.0, 7345.0, 7346.0, 7347.0, 7348.0, 7349.0, 7350.0,\n",
      "       7351.0],\n",
      "      dtype='float64', name='date', length=7352)\n",
      "(7352, 10)\n",
      "data\n",
      "(7352, 10)\n",
      "slice(None, 4411, None)\n",
      "slice(4411, 5881, None)\n",
      "slice(5881, None, None)\n",
      "(1, 7352, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/katoutsubasa/ts2vec/datautils.py:140: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data = pd.read_csv(f'datasets/{name}.csv', index_col='date', parse_dates=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datautils import _get_time_features,load_forecast_csv\n",
    "data, train_slice, valid_slice, test_slice, scaler, pred_lens, data1=load_forecast_csv(\"phone/phone_data_10\",False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "from ts2vec import TS2Vec\n",
    "ts2_model = TS2Vec(\n",
    "    input_dims=data.shape[-1],\n",
    "    length_dim=275,\n",
    "    device=\"cpu\",\n",
    "    output_dims=320,\n",
    "    input_total=1,\n",
    "    max_train_length=300,\n",
    "    #output_dims=10\n",
    ")\n",
    "ts2_model.load('phone_600_wind1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "all_repr = ts2_model.encode(\n",
    "        data,\n",
    "        causal=False,\n",
    "        sliding_length=1,\n",
    "        sliding_padding= 200,\n",
    "        batch_size=256,\n",
    "        #encoding_window='multiscale'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1279,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_2d = all_repr.reshape(7352, 320)\n",
    "test_2d=test_2d[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1280,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=torch.from_numpy(test_2d).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ファイルのパス\n",
    "file_path = 'datasets/phone/y_train.txt'\n",
    "\n",
    "# ファイルを読み込む\n",
    "with open(file_path, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# データをリストに変換\n",
    "data = []\n",
    "for line in lines:\n",
    "    # 行の空白を削除し、カンマで分割して浮動小数点数に変換\n",
    "    numbers = [float(num) for num in line.strip().split(',')]\n",
    "    data.append(numbers)\n",
    "\n",
    "# リストをPyTorchのテンソルに変換\n",
    "tensor_data = torch.tensor(data)[:1000]\n",
    "tensor_data=tensor_data.reshape(1000)\n",
    "y=tensor_data\n",
    "#print(tensor_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 320])\n",
      "torch.Size([1000])\n",
      "NaN in X: tensor(False)\n",
      "NaN in y: tensor(False)\n"
     ]
    }
   ],
   "source": [
    "# # ベクトルデータの定義\n",
    "# input_size = 320  # 入力ベクトルの次元\n",
    "# X = torch.randn(50, input_size)  # 50個の320次元ベクトル\n",
    "# y = torch.randint(0, 5, (50,))  # 0から4までのランダムなラベル\n",
    "print(X.size())\n",
    "print(y.size())\n",
    "print(\"NaN in X:\", torch.isnan(X).any())\n",
    "print(\"NaN in y:\", torch.isnan(y).any())\n",
    "\n",
    "class CustomVectorDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "# データセットとデータローダーの作成\n",
    "dataset = CustomVectorDataset(X, y)\n",
    "data_loader = DataLoader(dataset, batch_size=opt.batchSize, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データのロード\n",
    "def load_data(data_loader):\n",
    "    data = []\n",
    "    labels = []\n",
    "    for vectors, lbls in data_loader:\n",
    "        data.append(vectors)\n",
    "        labels.append(lbls)\n",
    "    data = torch.cat(data)\n",
    "    labels = torch.cat(labels)\n",
    "    return data, labels\n",
    "\n",
    "train_data, train_labels = load_data(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0643, -0.0273,  0.0131,  ...,  0.0094, -0.0192,  0.0237],\n",
      "        [ 0.0426, -0.0288, -0.0017,  ...,  0.0017, -0.0106,  0.0379],\n",
      "        [ 0.0571, -0.0314,  0.0136,  ..., -0.0117, -0.0029,  0.0341],\n",
      "        ...,\n",
      "        [ 0.0287, -0.0310,  0.0021,  ...,  0.0155,  0.0072,  0.0455],\n",
      "        [ 0.0610, -0.0193, -0.0018,  ...,  0.0281, -0.0224,  0.0546],\n",
      "        [ 0.0292, -0.0345, -0.0008,  ...,  0.0227,  0.0045,  0.0315]])\n"
     ]
    }
   ],
   "source": [
    "# if opt.centralize_input == 1:\n",
    "#     train_data -= train_data.mean(dim=0, keepdim=True)\n",
    "\n",
    "test_data = train_data.clone()\n",
    "test_labels = train_labels.clone()\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize networks\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.normal_(m.weight, 0, 0.01)\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "\n",
    "affinity = Affinity()\n",
    "evaluate = Evaluate()\n",
    "agg_clustering = AggClustering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1286,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(input_size):\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(input_size, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, 10)\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> configuring model\n"
     ]
    }
   ],
   "source": [
    "# Initialize CNN models and variables\n",
    "print('==> configuring model')\n",
    "num_networks = opt.num_nets\n",
    "network_table = []\n",
    "optimizer_table = []\n",
    "criterion_triplet = TripletEmbeddingCriterion(opt.margin_tr, opt.gamma_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1288,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(num_networks):\n",
    "    model = load_model(input_size)\n",
    "    model.apply(init_weights)\n",
    "    network_table.append(model)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=opt.learningRate, weight_decay=opt.weightDecay, momentum=opt.momentum)\n",
    "    optimizer_table.append(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1289,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_gt_table_table = []\n",
    "label_pre_table_table = []\n",
    "label_pre_tensor_table = []\n",
    "target_nclusters_table = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 6]\n"
     ]
    }
   ],
   "source": [
    "def cvt2TableLabels(labels):\n",
    "    unique_labels = torch.unique(labels)\n",
    "    label_table = {label.item(): [] for label in unique_labels}\n",
    "    for idx, label in enumerate(labels):\n",
    "        label_table[label.item()].append(idx)\n",
    "    return list(label_table.values())\n",
    "\n",
    "#print(cvt2TableLabels(test_labels))\n",
    "for _ in range(num_networks):\n",
    "    label_gt_table_table.append(cvt2TableLabels(test_labels))\n",
    "    label_pre_table_table.append([])\n",
    "    label_pre_tensor_table.append([])\n",
    "    target_nclusters_table.append(len(label_gt_table_table[-1]))\n",
    "print(target_nclusters_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1297,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "epoch_reset_labels = [0] * num_networks\n",
    "\n",
    "def getnClusters(label_pre):\n",
    "    nClusters = 0\n",
    "    for cluster in label_pre:\n",
    "        if len(cluster) > 0:\n",
    "            nClusters += 1\n",
    "    return nClusters\n",
    "\n",
    "def update_labels(features, label_pre, target_clusters, iter):\n",
    "    # print(\"compute affinity, \", features.size())\n",
    "    d, ind, W = affinity.compute(features, opt.K_s)  # sigma_l not used here\n",
    "    # sigma = sigma_l\n",
    "    if iter == 0:\n",
    "        print(\"initialize clusters...\")\n",
    "        # print(\"ind\", ind.size())\n",
    "        label_pre = agg_clustering.init(ind)\n",
    "        # print(\"nclusters: \", getnClusters(label_pre))\n",
    "        return label_pre\n",
    "\n",
    "    print(\"nclusters: \", getnClusters(label_pre))\n",
    "    A_us, A_s, label_pre = affinity.compute4cluster(features, W, label_pre, getnClusters(label_pre), target_clusters)\n",
    "    # print(\"nclusters affinity_compute: \", getnClusters(label_pre))\n",
    "    n_clusters = getnClusters(label_pre)\n",
    "    # print(\"A_s\", A_s.size())\n",
    "    # print(\"new_n_clusters\", n_clusters)\n",
    "    #12\n",
    "    print(\"run agglomerative clustering...\")\n",
    "\n",
    "    # Convert n_clusters to tensor\n",
    "    n_clusters_tensor = torch.tensor(n_clusters, dtype=torch.float32)\n",
    "    unfold_iter = torch.ceil(n_clusters_tensor * opt.eta).item()\n",
    "    unfold_valid_iter = n_clusters - target_clusters\n",
    "    iterations = min(unfold_iter, unfold_valid_iter)\n",
    "\n",
    "    if iterations <= 0:\n",
    "        print(\"nclusters:1Time: \", getnClusters(label_pre))\n",
    "        return label_pre\n",
    "\n",
    "    label_pre = agg_clustering.run(W, A_us, A_s, label_pre, iterations, opt.K_c, opt.use_fast)\n",
    "    return label_pre\n",
    "\n",
    "def extract_features(model, data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        features = []\n",
    "        for batch in DataLoader(CustomVectorDataset(data, torch.zeros(len(data))), batch_size=opt.batchSize, shuffle=False):\n",
    "            inputs, _ = batch\n",
    "            inputs = inputs\n",
    "            outputs = model(inputs)\n",
    "            features.append(outputs.cpu())\n",
    "    return torch.cat(features)\n",
    "\n",
    "def cvt2TensorLabels(labels):\n",
    "    tensor_labels = torch.zeros(sum(len(l) for l in labels), dtype=torch.long)\n",
    "    for cluster_id, cluster in enumerate(labels):\n",
    "        tensor_labels[cluster] = cluster_id + 1\n",
    "    return tensor_labels.unsqueeze(1)\n",
    "\n",
    "def merge_labels(network_table, epoch_reset_labels, train_data):\n",
    "    for i, model in enumerate(network_table):\n",
    "        if epoch_reset_labels[i] == 0 or opt.updateCNN == 0:\n",
    "            features = train_data\n",
    "        else:\n",
    "            features = extract_features(model, train_data)\n",
    "        \n",
    "        if opt.centralize_feature == 1:\n",
    "            features -= features.mean(dim=0, keepdim=True)\n",
    "        \n",
    "        if opt.normalize == 1:\n",
    "            features = nn.functional.normalize(features, p=2, dim=1)\n",
    "\n",
    "        print(\"feature dims:\", features.size())\n",
    "        label_pre_table_table[i] = update_labels(features, label_pre_table_table[i], target_nclusters_table[i], epoch_reset_labels[i])\n",
    "        epoch_reset_labels[i] += 1\n",
    "        nclusters = len(label_pre_table_table[i])\n",
    "        print(\"nclusters:\", nclusters)\n",
    "        label_pre_tensor_table[i] = cvt2TensorLabels(label_pre_table_table[i])\n",
    "\n",
    "def merge_labels_final():\n",
    "    for i, model in enumerate(network_table):\n",
    "        features = extract_features(model, train_data)\n",
    "        if opt.centralize_feature == 1:\n",
    "            features -= features.mean(dim=0, keepdim=True)\n",
    "        \n",
    "        if opt.normalize == 1:\n",
    "            features = nn.functional.normalize(features, p=2, dim=1)\n",
    "\n",
    "        label_pre_table_table[i] = update_labels(features, label_pre_table_table[i], target_nclusters_table[i], epoch_reset_labels[i])\n",
    "        epoch_reset_labels[i] += 1\n",
    "        nclusters = len(label_pre_table_table[i])\n",
    "        print(\"nclusters:\", nclusters)\n",
    "        label_pre_tensor_table[i] = cvt2TensorLabels(label_pre_table_table[i])\n",
    "\n",
    "def organize_samples(X, y):\n",
    "    num_s = X.size(0)\n",
    "    y_table = cvt2TableLabels(y)\n",
    "    nclusters = len(y_table)\n",
    "    if nclusters == 1:\n",
    "        return None, None\n",
    "    num_neg_sampling = min(opt.num_nsampling, nclusters - 1)\n",
    "    num_triplet = sum(len(cluster) * (len(cluster) - 1) * num_neg_sampling // 2 for cluster in y_table if len(cluster) > 1)\n",
    "    if num_triplet == 0:\n",
    "        return None, None\n",
    "\n",
    "    A = torch.zeros(num_triplet, X.size(1), device=X.device)\n",
    "    B = torch.zeros(num_triplet, X.size(1), device=X.device)\n",
    "    C = torch.zeros(num_triplet, X.size(1), device=X.device)\n",
    "    A_ind = torch.zeros(num_triplet, dtype=torch.long)\n",
    "    B_ind = torch.zeros(num_triplet, dtype=torch.long)\n",
    "    C_ind = torch.zeros(num_triplet, dtype=torch.long)\n",
    "    id_triplet = 0\n",
    "\n",
    "    for i, cluster in enumerate(y_table):\n",
    "        if len(cluster) > 1:\n",
    "            for m in range(len(cluster)):\n",
    "                for n in range(m + 1, len(cluster)):\n",
    "                    is_chosen = torch.zeros(num_s, dtype=torch.bool)\n",
    "                    chosen_count = 0\n",
    "                    while chosen_count < num_neg_sampling:\n",
    "                        id_s = random.randint(0, num_s - 1)\n",
    "                        if not is_chosen[id_s] and y[id_s] != y[cluster[m]]:\n",
    "                            A_ind[id_triplet] = cluster[m]\n",
    "                            B_ind[id_triplet] = cluster[n]\n",
    "                            C_ind[id_triplet] = id_s\n",
    "                            is_chosen[id_s] = True\n",
    "                            chosen_count += 1\n",
    "                            id_triplet += 1\n",
    "\n",
    "    A.copy_(X[A_ind])\n",
    "    B.copy_(X[B_ind])\n",
    "    C.copy_(X[C_ind])\n",
    "    return [A, B, C], [A_ind, B_ind, C_ind]\n",
    "\n",
    "def cvt2df_do(df_do, df_dtriplets, triplets_ind):\n",
    "    df_do.index_add_(0, triplets_ind[0], df_dtriplets[0])\n",
    "    df_do.index_add_(0, triplets_ind[1], df_dtriplets[1])\n",
    "    df_do.index_add_(0, triplets_ind[2], df_dtriplets[2])\n",
    "    return df_do\n",
    "\n",
    "# def update_CNN():\n",
    "#     for model, optimizer in zip(network_table, optimizer_table):\n",
    "#         model.train()\n",
    "#     epoch = 1\n",
    "#     print(f'==> online epoch # {epoch} [batchSize = {opt.batchSize}] [learningRate = {opt.learningRate}]')\n",
    "#     indices = torch.randperm(len(train_data)).split(opt.batchSize)\n",
    "\n",
    "#     for t, v in enumerate(indices, 1):\n",
    "#         iter = epoch * len(indices) + t - 1\n",
    "#         learning_rate = opt.learningRate * (1 + opt.gamma_lr * iter) ** -opt.power_lr\n",
    "#         for param_group in optimizer.param_groups:\n",
    "#             param_group['lr'] = learning_rate\n",
    "        \n",
    "#         inputs = train_data[v]\n",
    "#         targets = label_pre_tensor_table[0][v].squeeze()  # Change this if you have multiple networks\n",
    "        \n",
    "#         for model, optimizer in zip(network_table, optimizer_table):\n",
    "#             def closure():\n",
    "#                 optimizer.zero_grad()\n",
    "#                 outputs = model(inputs)\n",
    "#                 triplets, triplets_ind = organize_samples(outputs, targets)\n",
    "#                 loss = torch.tensor(0)\n",
    "#                 if triplets:\n",
    "#                     anchor, positive, negative = triplets\n",
    "#                     loss = criterion_triplet(anchor, positive, negative)\n",
    "#                     loss.backward()\n",
    "#                 if t % 10 == 0:\n",
    "#                     print(\"loss:\", loss.item())\n",
    "#                 return loss\n",
    "            \n",
    "#             optimizer.step(closure)\n",
    "#     epoch += 1\n",
    "\n",
    "def update_CNN(train_data):\n",
    "    for model in network_table:\n",
    "        model.train()\n",
    "    \n",
    "    global epoch\n",
    "    epoch = epoch if 'epoch' in globals() else 1\n",
    "    print(f'==> online epoch # {epoch} [batchSize = {opt.batchSize}] [learningRate = {opt.learningRate}]')\n",
    "    \n",
    "    indices = torch.randperm(len(train_data)).split(opt.batchSize)\n",
    "    \n",
    "    for t, v in enumerate(indices):\n",
    "        #print(f\"v: {v}, type: {type(v)}\")\n",
    "        iter = epoch * len(indices) + t\n",
    "        learning_rate = opt.learningRate * (1 + opt.gamma_lr * iter) ** (-opt.power_lr)\n",
    "        \n",
    "        inputs = train_data[v]\n",
    "        \n",
    "        for i, (model, optimizer) in enumerate(zip(network_table, optimizer_table)):\n",
    "            #print(label_pre_tensor_table)\n",
    "            #print(f\"i: {i}, type: {type(i)}\")\n",
    "            targets = label_pre_tensor_table[i][v]\n",
    "            \n",
    "            def closure():\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                \n",
    "                triplets, triplets_ind = organize_samples(outputs, targets.float())\n",
    "                #loss = torch.tensor(0.0)\n",
    "                if triplets is not None:\n",
    "                    anchor, positive, negative = triplets\n",
    "                    loss = criterion_triplet(anchor, positive, negative)\n",
    "                    #loss.backward()\n",
    "                \n",
    "                    if t % 10 == 0:\n",
    "                        print(\"loss:\", loss.item())\n",
    "                    return loss\n",
    "                else:\n",
    "                    return torch.tensor(0.0)\n",
    "            \n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = learning_rate\n",
    "            \n",
    "            optimizer.step(closure)\n",
    "    \n",
    "    epoch += 1\n",
    "\n",
    "def eval_perf():\n",
    "    for model in network_table:\n",
    "        model.eval()\n",
    "    print('==> testing')\n",
    "    for i, model in enumerate(network_table):\n",
    "        nmi = Evaluate().NMI(label_gt_table_table[i], label_pre_table_table[i])\n",
    "        print('NMI:', nmi)\n",
    "        print(\" \")\n",
    "\n",
    "def is_allfinished():\n",
    "    for label_pre, target_nclusters in zip(label_pre_table_table, target_nclusters_table):\n",
    "        if len(label_pre) > target_nclusters:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1298,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_reset_labels = [0] * num_networks\n",
    "optimState = {'learningRate': opt.learningRate}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature dims: torch.Size([1000, 320])\n",
      "Xtype torch.float32\n",
      "k 5\n",
      "now\n",
      "sigma: tensor(0.6083, dtype=torch.float64)\n",
      "initialize clusters...\n",
      "nclusters: 220\n",
      "==> testing\n",
      "NMI: 0.544594407081604\n",
      " \n",
      "==> online epoch # 686 [batchSize = 10] [learningRate = 0.01]\n",
      "loss: 0.19999614357948303\n",
      "==> online epoch # 687 [batchSize = 10] [learningRate = 0.01]\n",
      "loss: 0.19998885691165924\n",
      "==> online epoch # 688 [batchSize = 10] [learningRate = 0.01]\n",
      "loss: 0.19999651610851288\n",
      "loss: 0.1999945342540741\n",
      "loss: 0.19999244809150696\n",
      "==> online epoch # 689 [batchSize = 10] [learningRate = 0.01]\n",
      "loss: 0.19999904930591583\n",
      "loss: 0.19999191164970398\n",
      "==> online epoch # 690 [batchSize = 10] [learningRate = 0.01]\n",
      "loss: 0.19999592006206512\n",
      "loss: 0.1999954730272293\n",
      "==> online epoch # 691 [batchSize = 10] [learningRate = 0.01]\n",
      "loss: 0.19999748468399048\n",
      "loss: 0.19999785721302032\n",
      "loss: 0.19999568164348602\n",
      "loss: 0.20000728964805603\n",
      "==> online epoch # 692 [batchSize = 10] [learningRate = 0.01]\n",
      "loss: 0.19999663531780243\n",
      "==> online epoch # 693 [batchSize = 10] [learningRate = 0.01]\n",
      "loss: 0.1999967396259308\n",
      "==> online epoch # 694 [batchSize = 10] [learningRate = 0.01]\n",
      "loss: 0.19999705255031586\n",
      "loss: 0.1999969333410263\n",
      "loss: 0.19999344646930695\n",
      "==> online epoch # 695 [batchSize = 10] [learningRate = 0.01]\n",
      "loss: 0.1999954879283905\n",
      "==> online epoch # 696 [batchSize = 10] [learningRate = 0.01]\n",
      "==> online epoch # 697 [batchSize = 10] [learningRate = 0.01]\n",
      "loss: 0.19999366998672485\n",
      "loss: 0.19999662041664124\n",
      "loss: 0.19999410212039948\n",
      "loss: 0.19999441504478455\n",
      "loss: 0.19999657571315765\n",
      "loss: 0.19999337196350098\n",
      "==> online epoch # 698 [batchSize = 10] [learningRate = 0.01]\n",
      "loss: 0.1999981850385666\n",
      "==> online epoch # 699 [batchSize = 10] [learningRate = 0.01]\n",
      "loss: 0.19999662041664124\n",
      "loss: 0.19999468326568604\n",
      "loss: 0.19999371469020844\n",
      "loss: 0.19999532401561737\n",
      "==> online epoch # 700 [batchSize = 10] [learningRate = 0.01]\n",
      "loss: 0.1999937742948532\n",
      "loss: 0.19999447464942932\n",
      "==> online epoch # 701 [batchSize = 10] [learningRate = 0.01]\n",
      "loss: 0.19999177753925323\n",
      "loss: 0.19999554753303528\n",
      "loss: 0.19999709725379944\n",
      "==> online epoch # 702 [batchSize = 10] [learningRate = 0.01]\n",
      "loss: 0.19999852776527405\n",
      "loss: 0.19999490678310394\n",
      "loss: 0.19999392330646515\n",
      "==> online epoch # 703 [batchSize = 10] [learningRate = 0.01]\n",
      "==> online epoch # 704 [batchSize = 10] [learningRate = 0.01]\n",
      "loss: 0.19998274743556976\n",
      "loss: 0.19999639689922333\n",
      "loss: 0.19999566674232483\n",
      "loss: 0.19999438524246216\n",
      "==> online epoch # 705 [batchSize = 10] [learningRate = 0.01]\n",
      "loss: 0.19999104738235474\n",
      "feature dims: torch.Size([1000, 10])\n",
      "Xtype torch.float32\n",
      "k 5\n",
      "now\n",
      "sigma: tensor(0.5004, dtype=torch.float64)\n",
      "nclusters:  220\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1299], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(opt\u001b[38;5;241m.\u001b[39mepoch_max \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m opt\u001b[38;5;241m.\u001b[39mepoch_pp \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m----> 5\u001b[0m         \u001b[43mmerge_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnetwork_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch_reset_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m         eval_perf()\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m is_allfinished():\n",
      "Cell \u001b[0;32mIn[1297], line 74\u001b[0m, in \u001b[0;36mmerge_labels\u001b[0;34m(network_table, epoch_reset_labels, train_data)\u001b[0m\n\u001b[1;32m     71\u001b[0m     features \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mnormalize(features, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature dims:\u001b[39m\u001b[38;5;124m\"\u001b[39m, features\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m---> 74\u001b[0m label_pre_table_table[i] \u001b[38;5;241m=\u001b[39m \u001b[43mupdate_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_pre_table_table\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_nclusters_table\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch_reset_labels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m epoch_reset_labels[i] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     76\u001b[0m nclusters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(label_pre_table_table[i])\n",
      "Cell \u001b[0;32mIn[1297], line 22\u001b[0m, in \u001b[0;36mupdate_labels\u001b[0;34m(features, label_pre, target_clusters, iter)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m label_pre\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnclusters: \u001b[39m\u001b[38;5;124m\"\u001b[39m, getnClusters(label_pre))\n\u001b[0;32m---> 22\u001b[0m A_us, A_s, label_pre \u001b[38;5;241m=\u001b[39m \u001b[43maffinity\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute4cluster\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_pre\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgetnClusters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel_pre\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_clusters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# print(\"nclusters affinity_compute: \", getnClusters(label_pre))\u001b[39;00m\n\u001b[1;32m     24\u001b[0m n_clusters \u001b[38;5;241m=\u001b[39m getnClusters(label_pre)\n",
      "Cell \u001b[0;32mIn[1295], line 68\u001b[0m, in \u001b[0;36mAffinity.compute4cluster\u001b[0;34m(self, X, W, Y_0, k, k_target)\u001b[0m\n\u001b[1;32m     65\u001b[0m         Y_0_tensor[i][j] \u001b[38;5;241m=\u001b[39m Y_0[i][j]\n\u001b[1;32m     67\u001b[0m timer \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 68\u001b[0m A_unsym_0_c, A_sym_0_c \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_CAff\u001b[49m\u001b[43m(\u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNNs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_0_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m20\u001b[39m \u001b[38;5;241m*\u001b[39m k_target:\n\u001b[1;32m     71\u001b[0m     A_unsym_0_c \u001b[38;5;241m=\u001b[39m A_unsym_0_c\u001b[38;5;241m.\u001b[39mdouble()\n",
      "Cell \u001b[0;32mIn[1295], line 150\u001b[0m, in \u001b[0;36mAffinity.compute_CAff\u001b[0;34m(self, W, NNs, Y)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(Y_i_size):\n\u001b[1;32m    149\u001b[0m         s_W_c_j_i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m W[Y[j, m]\u001b[38;5;241m.\u001b[39mlong() \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, Y[i, n]\u001b[38;5;241m.\u001b[39mlong() \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m--> 150\u001b[0m         s_W_c_i_j \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m W[\u001b[43mY\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, Y[j, m]\u001b[38;5;241m.\u001b[39mlong() \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    151\u001b[0m     A_c_j_i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m s_W_c_i_j \u001b[38;5;241m*\u001b[39m s_W_c_j_i\n\u001b[1;32m    153\u001b[0m A_us[j, i] \u001b[38;5;241m=\u001b[39m A_c_i_j\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train multi-attribute discovery models\n",
    "for _ in range(opt.epoch_rnn):\n",
    "    for i in range(opt.epoch_max + 1):\n",
    "        if i % opt.epoch_pp == 0:\n",
    "            merge_labels(network_table, epoch_reset_labels, train_data)\n",
    "            eval_perf()\n",
    "            if is_allfinished():\n",
    "                break\n",
    "        if opt.updateCNN == 1:\n",
    "            update_CNN(train_data)\n",
    "    epoch_reset_labels = [0] * num_networks\n",
    "    while True:\n",
    "        merge_labels_final()\n",
    "        eval_perf()\n",
    "        if is_allfinished():\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: [[0, 177, 247, 350, 536, 773, 776, 768, 769, 771, 772, 774, 377, 998, 6, 358, 527, 609, 690, 694, 853, 992, 31, 180, 370, 700, 176, 995, 32, 67, 178, 246, 352, 357, 363, 369, 385, 693, 696, 996, 997, 179, 537, 689, 852, 353, 354, 355, 372, 553, 577, 15, 245, 381, 530, 533, 697, 712, 713, 849, 855, 367, 545, 718, 371, 541, 563, 858, 24, 34, 27, 380, 698, 889, 551, 701, 705, 869, 884, 887, 249, 434, 523, 564, 691, 778, 388, 539, 557, 558, 576, 526, 994, 183, 351, 368, 851, 25, 30, 73, 579, 703, 704, 714, 727, 730, 885, 62, 63, 74, 383, 384, 859, 863, 865, 72, 716, 71, 379, 386, 392, 724, 732, 864, 1, 7, 240, 528, 359, 854, 529, 695, 918, 2, 3, 241, 919, 360, 542, 856, 692, 848, 850, 993, 248, 349, 991, 4, 11, 75, 187, 204, 532, 182, 525, 565, 999, 396, 707, 876, 882, 20, 378, 397, 550, 723, 862, 877, 13, 181, 213, 524, 531, 775, 861, 47, 538, 741, 897, 191, 709, 356, 534, 546, 547, 568, 43, 48, 192, 742, 49, 586, 898, 190, 554, 373, 375, 562, 40, 428, 763, 195, 432, 752, 755, 912, 232, 739, 58, 411, 747, 901, 390, 399, 406, 581, 717, 733, 750, 866, 905, 66, 569, 711, 561, 720, 890, 184, 208, 189, 209, 214, 391, 549, 570, 593, 870, 874, 572, 702, 883, 395, 567, 578, 868, 878, 880, 21, 544, 559, 607, 737, 745, 857, 871, 892, 56, 235, 597, 608, 916, 221, 243, 760, 605, 761, 764, 22, 710, 721, 746, 904, 52, 226, 228, 738, 894, 403, 413, 893, 902, 427, 765, 205, 405, 595, 748, 903, 215, 414, 583, 404, 552, 556, 588, 725, 875, 26, 28, 37, 59, 61, 224, 407, 584, 900, 57, 230, 419, 420, 592, 412, 417, 426, 430, 600, 914, 421, 423, 60, 415, 582, 585, 587, 872, 36, 234, 416, 425, 591, 599, 881, 899, 53, 431, 589, 602, 227, 229, 389, 64, 210, 222, 735, 891, 895, 906, 909, 29, 382, 566, 729, 731, 364, 699, 886, 398, 409, 560, 571, 575, 580, 603, 715, 734, 736, 757, 860, 44, 45, 758, 418, 424, 604, 422, 756, 910, 911, 233, 574, 726, 873, 429, 594, 598, 601, 596, 606, 753, 759, 915, 917, 410, 749, 879, 206, 223, 5, 9, 33, 201, 35, 38, 42, 194, 212, 394, 535, 908, 10, 51, 55, 387, 770, 18, 217, 193, 200, 211, 219, 393, 400, 401, 408, 744, 41, 50, 242, 743, 590, 907, 913, 39, 231, 402, 751, 762, 896, 46, 199, 216, 220, 555, 188, 207, 548, 719, 867, 186, 203, 225, 365, 706, 722, 14, 23, 362, 366, 433, 540, 766, 888, 8, 16, 17, 65, 68, 69, 70, 185, 197, 244, 361, 376, 543, 12, 19, 374, 708, 740, 754, 54, 196, 198, 218, 202, 573, 728, 76, 77, 236, 767, 78, 435, 777, 174, 237, 250, 781, 239, 348], [168, 172, 255], [269, 277, 438, 441, 81, 256, 93, 108, 273, 790, 151, 157, 325, 328, 263, 437, 452, 680, 920, 152, 521, 154, 310, 313, 319, 681, 684, 307, 308, 86, 159, 326, 686, 329, 492, 496, 989, 84, 85, 611, 682, 679, 683, 158, 306, 312, 265, 272, 275, 317, 324, 347, 847, 264, 266, 80, 276, 780, 258, 449, 688, 444, 612, 617, 624, 445, 447, 613, 622, 623, 685, 443, 614, 446, 448, 107, 783, 625, 633, 117, 508, 675, 846, 112, 124, 454, 494, 495, 511, 512, 630, 635, 786, 628, 629, 637, 670, 116, 122, 287, 615, 114, 289, 513, 514, 515, 785, 791, 793, 92, 678, 104, 105, 500, 504, 509, 516, 290, 674, 98, 115, 283, 676, 292, 510, 673, 845, 88, 110, 280, 518, 91, 498, 517, 106, 632, 787, 501, 503, 271, 305, 311, 318, 101, 102, 631, 784, 925, 103, 288, 497, 792, 794, 923, 123, 304, 493, 921, 522, 687, 990, 82, 96, 119, 282, 285, 90, 109, 505, 95, 274, 278, 506, 253, 279, 442, 618, 621, 788, 789, 89, 94, 111, 284, 286, 616, 620, 924, 118, 261, 281, 309, 315, 316, 507, 153, 260, 270, 322, 323, 83, 150, 97, 262, 267, 268, 519, 619, 120, 121, 490, 167, 254, 436, 440, 163, 164, 165, 166, 321, 520, 155, 160, 161, 320, 156, 327, 87, 252, 259, 439, 162, 171, 450, 782, 79, 251, 257, 314, 301, 502, 666, 667, 795, 844, 668, 669, 113, 672, 149, 302, 345, 489, 664, 665, 671, 988, 291, 303, 499, 677, 125, 296, 297, 330, 334, 638, 639, 640, 646, 647, 648, 649, 643, 644, 645, 148, 343, 344, 126, 146, 339, 127, 129, 130, 133, 135, 136, 139, 140, 144, 145, 335, 336, 663, 134, 138, 141, 142, 337, 338, 340, 131, 147, 331, 332, 341, 128, 333, 342, 468, 652, 132, 143, 642, 137, 467, 472, 641, 650, 651, 477, 478, 298, 465, 466, 469, 470, 475, 488, 655, 660, 796, 945, 471, 476, 659, 653, 656, 661, 798, 801, 808, 809, 473, 474, 654, 657, 799, 800, 804, 805, 806, 807, 813, 658, 944, 818, 946, 961, 966, 951, 954, 960, 965, 482, 483, 950, 957, 963, 964, 968, 481, 934, 949, 959, 952, 955, 956, 962, 969, 947, 953, 958, 967, 823, 935, 480, 484, 487, 948, 810, 814, 816, 817, 819, 802, 803, 812, 820, 821, 811, 815, 479, 662, 822, 975, 453, 634, 99, 100, 293, 346, 456, 463, 491, 626, 927, 460, 461, 458, 459, 294, 295, 455, 922, 627, 636, 457, 462, 464, 926, 299, 300, 797, 839, 840, 929, 824, 831, 833, 841, 928, 930, 837, 842, 931, 940, 941, 943, 985, 986, 987, 825, 827, 826, 828, 829, 835, 838, 832, 834, 843, 830, 836, 932, 942, 978, 984, 936, 937, 971, 977, 979, 938, 939, 972, 980, 981, 485, 486, 974, 933, 982, 970, 973, 976, 983], [173, 451], [175, 238, 610], [169, 170, 779]]\n"
     ]
    }
   ],
   "source": [
    "# 最終的なクラスタリング結果を取得\n",
    "final_clusters = label_pre_table_table\n",
    "\n",
    "# クラスタリング結果を表示\n",
    "for cluster_id, cluster in enumerate(final_clusters):\n",
    "    print(f\"Cluster {cluster_id}: {cluster}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945]\n",
      "[150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989]\n",
      "[125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 296, 297, 298, 299, 300, 301, 302, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967]\n",
      "[27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999]\n",
      "[51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919]\n"
     ]
    }
   ],
   "source": [
    "#正解ラベルの表示\n",
    "#print(label_gt_table_table[0])\n",
    "for i in label_gt_table_table[0]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted list 0: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 781, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 991, 992, 993, 994, 995, 996, 997, 998, 999]\n",
      "Sorted list 1: [168, 172, 255]\n",
      "Sorted list 2: [79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 171, 251, 252, 253, 254, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 780, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990]\n",
      "Sorted list 3: [173, 451]\n",
      "Sorted list 4: [175, 238, 610]\n",
      "Sorted list 5: [169, 170, 779]\n"
     ]
    }
   ],
   "source": [
    "sorted_data = []\n",
    "#print(final_clusters)\n",
    "for sublist in final_clusters[0]:\n",
    "    #print(sublist)\n",
    "    if isinstance(sublist, list):\n",
    "        sorted_data.append(sorted(sublist))\n",
    "#print(sorted_data)\n",
    "\n",
    "#予測結果の表示\n",
    "for i, sublist in enumerate(sorted_data):\n",
    "    print(f\"Sorted list {i}: {sublist}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6]\n"
     ]
    }
   ],
   "source": [
    "print(target_nclusters_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tstest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
